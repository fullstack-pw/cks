# Phase 1: Infrastructure & Core Models Implementation

## Overview
**Timeline**: Days 1-3  
**Goal**: Set up the foundational infrastructure and data models for the cluster pool system  
**Approach**: Bootstrap all 3 clusters initially to have a fully ready pool

---

## Task 1: Create ClusterPool Data Models

### File: `backend/internal/models/models.go`

#### Add New Types
```go
// ClusterPool represents a managed cluster in the pool
type ClusterPool struct {
    ClusterID       string        `json:"clusterId"`       // "cluster1", "cluster2", "cluster3"
    Namespace       string        `json:"namespace"`       // matches clusterID
    Status          ClusterStatus `json:"status"`
    AssignedSession string        `json:"assignedSession,omitempty"`
    LockTime        time.Time     `json:"lockTime,omitempty"`
    LastReset       time.Time     `json:"lastReset"`
    ControlPlaneVM  string        `json:"controlPlaneVM"`  // e.g., "cp-cluster1"
    WorkerNodeVM    string        `json:"workerNodeVM"`    // e.g., "wk-cluster1"
    CreatedAt       time.Time     `json:"createdAt"`
    LastHealthCheck time.Time     `json:"lastHealthCheck"`
}

// ClusterStatus represents the state of a cluster in the pool
type ClusterStatus string

const (
    StatusAvailable ClusterStatus = "available"  // Ready for assignment
    StatusLocked    ClusterStatus = "locked"     // Currently assigned to session
    StatusResetting ClusterStatus = "resetting"  // Being restored from snapshot
    StatusError     ClusterStatus = "error"      // Needs manual intervention
    StatusCreating  ClusterStatus = "creating"   // Initial bootstrap in progress
)

// ClusterPoolStats provides pool-wide statistics
type ClusterPoolStats struct {
    TotalClusters     int                       `json:"totalClusters"`
    AvailableClusters int                       `json:"availableClusters"`
    LockedClusters    int                       `json:"lockedClusters"`
    ResettingClusters int                       `json:"resettingClusters"`
    ErrorClusters     int                       `json:"errorClusters"`
    StatusByCluster   map[string]ClusterStatus  `json:"statusByCluster"`
}
```

#### Update Session Model
```go
// Add to existing Session struct
type Session struct {
    // ... existing fields
    AssignedCluster  string    `json:"assignedCluster,omitempty"`  // "cluster1", "cluster2", "cluster3"
    ClusterLockTime  time.Time `json:"clusterLockTime,omitempty"`
}
```

**Acceptance Criteria:**
- [ ] ClusterPool model defined with all required fields
- [ ] ClusterStatus enum with all states defined
- [ ] Session model updated with cluster assignment fields
- [ ] Code compiles without errors

---

## Task 2: Create 3 Static Cluster Namespaces

Adapt existing function to handle cluster1 2 and 3 namespaces and if it already exists it should proceed.

**Acceptance Criteria:**
- [ ] `vm-templates` namespace exists with proper labels
- [ ] `cluster1`, `cluster2`, `cluster3` namespaces exist with proper labels
- [ ] namespace function adapted

---

## Task 3: Bootstrap 3 Baseline Clusters

### Backend Endpoint: `/api/v1/admin/bootstrap-pool`

This task requires adding a new admin endpoint that bootstraps the cluster pool using the already existent working provisionFromBootstrap.

**Acceptance Criteria:**
- [ ] New admin endpoint `/api/v1/admin/bootstrap-pool` implemented
- [ ] 3 clusters bootstrap test
- [ ] All clusters accessible via kubectl/virtctl after bootstrap

---

## Task 4: Create Golden Snapshots

This task require a new shell script to create the golden snapshots

**Key Changes:**
- Snapshots created in **same namespace** as VMs (no cross-namespace)
- Short snapshot names: `cp-snap`, `wk-snap` to avoid 63-char limit
- Auto-discover VM names using kubectl since they're short random names
- Add labels for cluster identification

**Acceptance Criteria:**
- [ ] 6 snapshots total (2 per cluster) in their respective cluster namespaces
- [ ] All snapshots in `Ready` state
- [ ] Snapshots properly labeled with cluster-id and vm-role
- [ ] Original VMs still running after snapshot creation

---

## Task 5: Create ClusterPoolManager Structure

### File: `backend/internal/clusterpool/manager.go`

```go
// backend/internal/clusterpool/manager.go
package clusterpool

import (
    "context"
    "fmt"
    "sync"
    "time"

    "github.com/fullstack-pw/cks/backend/internal/config"
    "github.com/fullstack-pw/cks/backend/internal/kubevirt"
    "github.com/fullstack-pw/cks/backend/internal/models"
    "github.com/sirupsen/logrus"
    "k8s.io/client-go/kubernetes"
)

const (
    PoolSize = 3 // cluster1, cluster2, cluster3
)

// Manager manages the cluster pool for session assignment
type Manager struct {
    clusters       map[string]*models.ClusterPool
    lock          sync.RWMutex
    kubeClient    kubernetes.Interface
    kubevirtClient *kubevirt.Client
    config        *config.Config
    logger        *logrus.Logger
    
    // Background task control
    stopCh        chan struct{}
}

// NewManager creates a new cluster pool manager
func NewManager(
    cfg *config.Config,
    kubeClient kubernetes.Interface,
    kubevirtClient *kubevirt.Client,
    logger *logrus.Logger,
) (*Manager, error) {
    manager := &Manager{
        clusters:       make(map[string]*models.ClusterPool, PoolSize),
        kubeClient:     kubeClient,
        kubevirtClient: kubevirtClient,
        config:         cfg,
        logger:         logger,
        stopCh:         make(chan struct{}),
    }

    // Initialize the pool
    if err := manager.initializePool(context.Background()); err != nil {
        return nil, fmt.Errorf("failed to initialize cluster pool: %w", err)
    }

    // Start background maintenance
    go manager.maintenanceLoop()

    return manager, nil
}

// initializePool sets up the initial cluster pool state
func (m *Manager) initializePool(ctx context.Context) error {
    m.logger.Info("Initializing cluster pool...")

    clusterIDs := []string{"cluster1", "cluster2", "cluster3"}
    
    for _, clusterID := range clusterIDs {
        // Discover actual VM names in the cluster (they're short random names)
        controlPlaneVM, workerVM, err := m.discoverVMNames(ctx, clusterID)
        if err != nil {
            m.logger.WithError(err).WithField("clusterID", clusterID).Warn("Could not discover VMs, using placeholder names")
            // Use placeholder names - will be updated when VMs are actually created
            controlPlaneVM = fmt.Sprintf("cp-placeholder-%s", clusterID)
            workerVM = fmt.Sprintf("wk-placeholder-%s", clusterID)
        }
        
        cluster := &models.ClusterPool{
            ClusterID:      clusterID,
            Namespace:      clusterID, // namespace matches cluster ID
            Status:         models.StatusAvailable,
            ControlPlaneVM: controlPlaneVM,
            WorkerNodeVM:   workerVM,
            CreatedAt:      time.Now(),
            LastReset:      time.Now(),
        }
        
        m.clusters[clusterID] = cluster
        
        m.logger.WithFields(logrus.Fields{
            "clusterID": clusterID,
            "namespace": cluster.Namespace,
            "controlPlaneVM": cluster.ControlPlaneVM,
            "workerVM": cluster.WorkerNodeVM,
        }).Info("Cluster added to pool")
    }

    m.logger.WithField("poolSize", len(m.clusters)).Info("Cluster pool initialized")
    return nil
}

// discoverVMNames finds the actual VM names in a cluster namespace
func (m *Manager) discoverVMNames(ctx context.Context, clusterID string) (string, string, error) {
    namespace := clusterID
    
    // Try to find VMs by label first
    vms, err := m.kubeClient.CoreV1().Pods(namespace).List(ctx, metav1.ListOptions{
        LabelSelector: "kubevirt.io=virt-launcher",
    })
    if err != nil {
        return "", "", fmt.Errorf("failed to list pods in %s: %w", namespace, err)
    }
    
    // Alternative: use kubectl-like approach to find VMs
    // For now, return error so we use placeholder names
    return "", "", fmt.Errorf("VM discovery not implemented yet")
}

// UpdateVMNames updates the VM names for a cluster after they're created
func (m *Manager) UpdateVMNames(clusterID, controlPlaneVM, workerVM string) {
    m.lock.Lock()
    defer m.lock.Unlock()
    
    if cluster, exists := m.clusters[clusterID]; exists {
        cluster.ControlPlaneVM = controlPlaneVM
        cluster.WorkerNodeVM = workerVM
        
        m.logger.WithFields(logrus.Fields{
            "clusterID": clusterID,
            "controlPlaneVM": controlPlaneVM,
            "workerVM": workerVM,
        }).Info("Updated VM names for cluster")
    }
}

// AssignCluster assigns an available cluster to a session
func (m *Manager) AssignCluster(sessionID string) (*models.ClusterPool, error) {
    m.lock.Lock()
    defer m.lock.Unlock()

    // Find first available cluster
    for clusterID, cluster := range m.clusters {
        if cluster.Status == models.StatusAvailable {
            // Lock cluster to session
            cluster.Status = models.StatusLocked
            cluster.AssignedSession = sessionID
            cluster.LockTime = time.Now()
            
            m.logger.WithFields(logrus.Fields{
                "clusterID": clusterID,
                "sessionID": sessionID,
            }).Info("Cluster assigned to session")
            
            return cluster, nil
        }
    }

    return nil, fmt.Errorf("no available clusters in pool")
}

// ReleaseCluster releases a cluster from a session
func (m *Manager) ReleaseCluster(sessionID string) error {
    m.lock.Lock()
    defer m.lock.Unlock()

    // Find cluster assigned to this session
    for clusterID, cluster := range m.clusters {
        if cluster.AssignedSession == sessionID {
            // Mark for reset
            cluster.Status = models.StatusResetting
            cluster.AssignedSession = ""
            cluster.LockTime = time.Time{}
            
            m.logger.WithFields(logrus.Fields{
                "clusterID": clusterID,
                "sessionID": sessionID,
            }).Info("Cluster released and marked for reset")
            
            // Trigger async reset
            go m.resetClusterAsync(clusterID)
            
            return nil
        }
    }

    return fmt.Errorf("no cluster found for session %s", sessionID)
}

// GetPoolStatus returns current pool statistics
func (m *Manager) GetPoolStatus() *models.ClusterPoolStats {
    m.lock.RLock()
    defer m.lock.RUnlock()

    stats := &models.ClusterPoolStats{
        TotalClusters:   len(m.clusters),
        StatusByCluster: make(map[string]models.ClusterStatus),
    }

    for clusterID, cluster := range m.clusters {
        stats.StatusByCluster[clusterID] = cluster.Status
        
        switch cluster.Status {
        case models.StatusAvailable:
            stats.AvailableClusters++
        case models.StatusLocked:
            stats.LockedClusters++
        case models.StatusResetting:
            stats.ResettingClusters++
        case models.StatusError:
            stats.ErrorClusters++
        }
    }

    return stats
}

// resetClusterAsync performs cluster reset in background
func (m *Manager) resetClusterAsync(clusterID string) {
    m.logger.WithField("clusterID", clusterID).Info("Starting cluster reset")
    
    // TODO: Implement snapshot-based reset in Phase 2
    // For now, just mark as available after a delay
    time.Sleep(10 * time.Second)
    
    m.lock.Lock()
    if cluster, exists := m.clusters[clusterID]; exists {
        cluster.Status = models.StatusAvailable
        cluster.LastReset = time.Now()
    }
    m.lock.Unlock()
    
    m.logger.WithField("clusterID", clusterID).Info("Cluster reset completed")
}

// maintenanceLoop performs periodic maintenance tasks
func (m *Manager) maintenanceLoop() {
    ticker := time.NewTicker(5 * time.Minute)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            m.performMaintenance()
        case <-m.stopCh:
            return
        }
    }
}

// performMaintenance checks cluster health and performs cleanup
func (m *Manager) performMaintenance() {
    m.lock.RLock()
    defer m.lock.RUnlock()

    m.logger.Debug("Performing cluster pool maintenance")
    
    for clusterID, cluster := range m.clusters {
        cluster.LastHealthCheck = time.Now()
        // TODO: Add health checks in later phases
        
        m.logger.WithFields(logrus.Fields{
            "clusterID": clusterID,
            "status": cluster.Status,
            "assignedSession": cluster.AssignedSession,
        }).Debug("Cluster maintenance check")
    }
}

// Stop gracefully shuts down the cluster pool manager
func (m *Manager) Stop() {
    close(m.stopCh)
    m.logger.Info("Cluster pool manager stopped")
}
```usterID, cluster := range m.clusters {
        if cluster.Status == models.StatusAvailable {
            // Lock cluster to session
            cluster.Status = models.StatusLocked
            cluster.AssignedSession = sessionID
            cluster.LockTime = time.Now()
            
            m.logger.WithFields(logrus.Fields{
                "clusterID": clusterID,
                "sessionID": sessionID,
            }).Info("Cluster assigned to session")
            
            return cluster, nil
        }
    }

    return nil, fmt.Errorf("no available clusters in pool")
}

// ReleaseCluster releases a cluster from a session
func (m *Manager) ReleaseCluster(sessionID string) error {
    m.lock.Lock()
    defer m.lock.Unlock()

    // Find cluster assigned to this session
    for clusterID, cluster := range m.clusters {
        if cluster.AssignedSession == sessionID {
            // Mark for reset
            cluster.Status = models.StatusResetting
            cluster.AssignedSession = ""
            cluster.LockTime = time.Time{}
            
            m.logger.WithFields(logrus.Fields{
                "clusterID": clusterID,
                "sessionID": sessionID,
            }).Info("Cluster released and marked for reset")
            
            // Trigger async reset
            go m.resetClusterAsync(clusterID)
            
            return nil
        }
    }

    return fmt.Errorf("no cluster found for session %s", sessionID)
}

// GetPoolStatus returns current pool statistics
func (m *Manager) GetPoolStatus() *models.ClusterPoolStats {
    m.lock.RLock()
    defer m.lock.RUnlock()

    stats := &models.ClusterPoolStats{
        TotalClusters:   len(m.clusters),
        StatusByCluster: make(map[string]models.ClusterStatus),
    }

    for clusterID, cluster := range m.clusters {
        stats.StatusByCluster[clusterID] = cluster.Status
        
        switch cluster.Status {
        case models.StatusAvailable:
            stats.AvailableClusters++
        case models.StatusLocked:
            stats.LockedClusters++
        case models.StatusResetting:
            stats.ResettingClusters++
        case models.StatusError:
            stats.ErrorClusters++
        }
    }

    return stats
}

// resetClusterAsync performs cluster reset in background
func (m *Manager) resetClusterAsync(clusterID string) {
    m.logger.WithField("clusterID", clusterID).Info("Starting cluster reset")
    
    // TODO: Implement snapshot-based reset in Phase 2
    // For now, just mark as available after a delay
    time.Sleep(10 * time.Second)
    
    m.lock.Lock()
    if cluster, exists := m.clusters[clusterID]; exists {
        cluster.Status = models.StatusAvailable
        cluster.LastReset = time.Now()
    }
    m.lock.Unlock()
    
    m.logger.WithField("clusterID", clusterID).Info("Cluster reset completed")
}

// maintenanceLoop performs periodic maintenance tasks
func (m *Manager) maintenanceLoop() {
    ticker := time.NewTicker(5 * time.Minute)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            m.performMaintenance()
        case <-m.stopCh:
            return
        }
    }
}

// performMaintenance checks cluster health and performs cleanup
func (m *Manager) performMaintenance() {
    m.lock.RLock()
    defer m.lock.RUnlock()

    m.logger.Debug("Performing cluster pool maintenance")
    
    for clusterID, cluster := range m.clusters {
        cluster.LastHealthCheck = time.Now()
        // TODO: Add health checks in later phases
        
        m.logger.WithFields(logrus.Fields{
            "clusterID": clusterID,
            "status": cluster.Status,
            "assignedSession": cluster.AssignedSession,
        }).Debug("Cluster maintenance check")
    }
}

// Stop gracefully shuts down the cluster pool manager
func (m *Manager) Stop() {
    close(m.stopCh)
    m.logger.Info("Cluster pool manager stopped")
}
```

**Acceptance Criteria:**
- [ ] ClusterPoolManager struct created with all required methods
- [ ] Pool initializes with 3 clusters on startup
- [ ] Assignment logic implemented (returns first available cluster)
- [ ] Release logic implemented (marks cluster for reset)
- [ ] Background maintenance loop running
- [ ] Proper logging and error handling

---

## Phase 1 Completion Checklist

- [ ] **Task 1**: ClusterPool models added to `models.go`
- [ ] **Task 2**: 3 cluster namespaces created with proper labels
- [ ] **Task 3**: 3 baseline Kubernetes clusters bootstrapped and running
- [ ] **Task 4**: 6 golden snapshots created in `vm-templates` namespace
- [ ] **Task 5**: ClusterPoolManager implemented with basic assignment logic

**Validation Steps:**
1. Run `kubectl get namespaces -l cks.io/cluster-pool=true` → Should show 3 clusters
2. Run `kubectl get vmsnapshot -n vm-templates` → Should show 6 snapshots
3. Compile backend code → Should build without errors
4. Check cluster health → All clusters should be accessible

**Ready for Phase 2**: Pool management logic implementation